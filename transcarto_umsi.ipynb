{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple inference notebook for testing UMSI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Requirements for running models:\n",
    "\n",
    "# conda install python=3.6.9\n",
    "# conda install -c conda-forge keras=2.3.1\n",
    "# conda install -c conda-forge tensorflow-gpu=1.14.0\n",
    "\n",
    "# if there's a driver incompatability (check cudatoolkit version and compare to cuda version listed by nvidia-smi)\n",
    "# might need to reinstall: conda install pytorch==1.2.0 torchvision==0.4.0 cudatoolkit=10.0 -c pytorch \n",
    "\n",
    "# and one of the following two image processing libraries (both not necessary):\n",
    "# (option 1) conda install -c conda-forge opencv \n",
    "# (option 2) conda install -c conda-forge scikit-image\n",
    "\n",
    "# other dependencies:\n",
    "# conda install -c anaconda pillow\n",
    "# conda install -c conda-forge matplotlib\n",
    "# conda install -c anaconda scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.utils.data_utils import get_file\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import sys\n",
    "import os\n",
    "# import keras.backend as K\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Model\n",
    "from PIL import Image\n",
    "import scipy\n",
    "import requests\n",
    "\n",
    "# choose which image processing library you want to use\n",
    "use_cv2 = False \n",
    "if use_cv2:\n",
    "    import cv2\n",
    "else:\n",
    "    import skimage.transform as skit\n",
    "# ---------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aux functions\n",
    "\n",
    "# Input shape of the model\n",
    "shape_r=240\n",
    "shape_c=320\n",
    "\n",
    "def padding(img, shape_r, shape_c, channels=3):\n",
    "    img_padded = np.zeros((shape_r, shape_c, channels), dtype=np.uint8)\n",
    "    if channels == 1:\n",
    "        img_padded = np.zeros((shape_r, shape_c), dtype=np.uint8)\n",
    "    if use_cv2:\n",
    "        original_shape = img.shape\n",
    "    else:\n",
    "        original_shape = np.asarray(img).shape\n",
    "    rows_rate = original_shape[0]/shape_r\n",
    "    cols_rate = original_shape[1]/shape_c\n",
    "\n",
    "    if rows_rate > cols_rate:\n",
    "        new_cols = (original_shape[1] * shape_r) // original_shape[0]\n",
    "        if use_cv2:\n",
    "            img = cv2.resize(img, (new_cols, shape_r))\n",
    "        else:\n",
    "            img = img.resize((new_cols, shape_r))\n",
    "        if new_cols > shape_c:\n",
    "            new_cols = shape_c\n",
    "        img_padded[:, ((img_padded.shape[1] - new_cols) // 2):((img_padded.shape[1] - new_cols) // 2 + new_cols)] = img\n",
    "    else:\n",
    "        new_rows = (original_shape[0] * shape_c) // original_shape[1]\n",
    "        if use_cv2:\n",
    "            img = cv2.resize(img, (shape_c, new_rows))\n",
    "        else:\n",
    "            img = img.resize((shape_c, new_rows))\n",
    "        if new_rows > shape_r:\n",
    "            new_rows = shape_r\n",
    "        img_padded[((img_padded.shape[0] - new_rows) // 2):((img_padded.shape[0] - new_rows) // 2 + new_rows), :] = img\n",
    "\n",
    "    return img_padded\n",
    "\n",
    "def preprocess_images(paths, shape_r, shape_c, pad=True, show=False):\n",
    "    if pad:\n",
    "        ims = np.zeros((len(paths), shape_r, shape_c, 3))\n",
    "    else:\n",
    "        ims =[]\n",
    "\n",
    "    for i, path in enumerate(paths):\n",
    "        if use_cv2:\n",
    "            original_image = cv2.imread(path)\n",
    "        else:\n",
    "            original_image = Image.open(path)\n",
    "        if original_image is None:\n",
    "            raise ValueError('Path unreadable: %s' % path)\n",
    "        if pad:\n",
    "            padded_image = padding(original_image, shape_r, shape_c, 3)\n",
    "            ims[i] = padded_image\n",
    "        else:\n",
    "            original_image = original_image.astype(np.float32)\n",
    "            original_image[..., 0] -= 103.939\n",
    "            original_image[..., 1] -= 116.779\n",
    "            original_image[..., 2] -= 123.68\n",
    "            ims.append(original_image)\n",
    "            ims = np.array(ims)\n",
    "            print('ims.shape in preprocess_imgs',ims.shape)\n",
    "            \n",
    "        if show:\n",
    "            print(\"Path:\", path)\n",
    "            plt.figure(figsize=[8,8])\n",
    "            plt.subplot(1,2,1)\n",
    "            if use_cv2:\n",
    "                plt.imshow(cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB))\n",
    "            else:\n",
    "                plt.imshow(original_image)\n",
    "            plt.title(\"Original image\")\n",
    "            plt.subplot(1,2,2)\n",
    "            if use_cv2:\n",
    "                plt.imshow(cv2.cvtColor(padded_image, cv2.COLOR_BGR2RGB))\n",
    "            else:\n",
    "                plt.imshow(padded_image)\n",
    "            plt.title(\"Input to network\")\n",
    "            plt.show()\n",
    "\n",
    "    if pad:\n",
    "        ims[:, :, :, 0] -= 103.939\n",
    "        ims[:, :, :, 1] -= 116.779\n",
    "        ims[:, :, :, 2] -= 123.68\n",
    "\n",
    "    return ims\n",
    "\n",
    "def postprocess_predictions(pred, shape_r, shape_c, blur=False, normalize=False):\n",
    "    predictions_shape = pred.shape\n",
    "    rows_rate = shape_r / predictions_shape[0]\n",
    "    cols_rate = shape_c / predictions_shape[1]\n",
    "\n",
    "    if blur:\n",
    "        sigma=blur\n",
    "        pred = scipy.ndimage.filters.gaussian_filter(pred, sigma=sigma)\n",
    "\n",
    "    if rows_rate > cols_rate:\n",
    "        new_cols = (predictions_shape[1] * shape_r) // predictions_shape[0]\n",
    "        if use_cv2:\n",
    "            pred = cv2.resize(pred, (new_cols, shape_r))\n",
    "        else:\n",
    "            pred = skit.resize(pred, (shape_r, new_cols))\n",
    "        img = pred[:, ((pred.shape[1] - shape_c) // 2):((pred.shape[1] - shape_c) // 2 + shape_c)]\n",
    "    else:\n",
    "        new_rows = (predictions_shape[0] * shape_c) // predictions_shape[1]\n",
    "        if use_cv2:\n",
    "            pred = cv2.resize(pred, (shape_c, new_rows))\n",
    "        else:\n",
    "            pred = skit.resize(pred, (new_rows, shape_c))\n",
    "        img = pred[((pred.shape[0] - shape_r) // 2):((pred.shape[0] - shape_r) // 2 + shape_r), :]\n",
    "\n",
    "    if normalize:\n",
    "        img = img / np.max(img) * 255\n",
    "\n",
    "    return img\n",
    "\n",
    "\n",
    "def heatmap_overlay(im,heatmap,colmap='hot'):\n",
    "    cm_array = cm.get_cmap(colmap)\n",
    "    im_array = np.asarray(im)\n",
    "    heatmap_norm = (heatmap-np.min(heatmap))/float(np.max(heatmap)-np.min(heatmap))\n",
    "    heatmap_hot = cm_array(heatmap_norm)\n",
    "    res_final = im_array.copy()\n",
    "    heatmap_rep = np.repeat(heatmap_norm[:, :, np.newaxis], 3, axis=2)\n",
    "    res_final[...] = heatmap_hot[...,0:3]*255.0*heatmap_rep + im_array[...]*(1-heatmap_rep)\n",
    "    return res_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load model\n",
    "# the model can be downloaded from here: http://predimportance.mit.edu/data/xception_cl_fus_aspp_imp1k_10kl-3cc0.1mse-5nss5bc_bs4_ep30_valloss-2.5774_full.h5\n",
    "#ckpt_path = '/Users/laurentjegou/Documents/test/predimportance-public-master/xception_cl_fus_aspp_imp1k_10kl-3cc0.1mse-5nss5bc_bs4_ep30_valloss-2.5774_full.h5'     \n",
    "\n",
    "url = 'https://www.geotests.net/depot/xception_cl_fus_aspp_imp1k_10kl-3cc0.1mse-5nss5bc_bs4_ep30_valloss-2.5774_full.h5'\n",
    "ckpt_path = get_file('ckpt',url)\n",
    "\n",
    "# model = keras.models.load_model(ckpt_path, compile=False)\n",
    "model = tf.keras.models.load_model(ckpt_path, compile=False, custom_objects={'K': K})\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in the paths for the images you want to test here, natural images or graphic designs (both work!)\n",
    "# Paths must be URLs to JPEG files only!\n",
    "\n",
    "image1_url = 'https://www.geotests.net/depot/160_Afrique_Ctg%202000-2050_Pop%20Agee.jpg'\n",
    "image2_url = 'https://www.geotests.net/depot/winds.jpg'\n",
    "img_paths = [image1_url, image2_url]\n",
    "\n",
    "image1 = requests.get(image1_url, stream=True).raw\n",
    "image2 = requests.get(image2_url, stream=True).raw\n",
    "\n",
    "imgs = [image1, image2]\n",
    "\n",
    "img_batch = preprocess_images(imgs, shape_r, shape_c, pad=True, show=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(img_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Show predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill this in if images have ground truth and you want to see them side by side for comparison\n",
    "gr_truth_paths = None\n",
    "\n",
    "if gr_truth_paths is not None: k=4;\n",
    "else: k=3;\n",
    "\n",
    "\n",
    "pred_batch=[]\n",
    "for i in range(len(img_paths)):\n",
    "\n",
    "    # Open original image to get width and height\n",
    "    limage = requests.get(img_paths[i], stream=True).raw\n",
    "    im = Image.open(limage)\n",
    "    width, height = im.size\n",
    "    \n",
    "    # Postprocess to get pred back to original size\n",
    "    pred_batch.append(postprocess_predictions(pred[0][i,:,:,0], height, width))\n",
    "    \n",
    "    # Overlay heatmap on image\n",
    "    res = heatmap_overlay(im,pred_batch[i],'viridis');\n",
    "    \n",
    "    # Show\n",
    "    plt.figure(figsize=[15,15])\n",
    "    plt.subplot(1,k,1)\n",
    "    plt.imshow(im)\n",
    "    plt.title(\"Original image\")\n",
    "    plt.subplot(1,k,2)\n",
    "    plt.imshow(pred_batch[i])\n",
    "    plt.title(\"Prediction\")\n",
    "    plt.subplot(1,k,3)\n",
    "    plt.imshow(res)\n",
    "    #plt.savefig(img_paths[i]+'_umsi'+'.png', bbox_inches='tight')\n",
    "    plt.title(\"Prediction overlaid\")\n",
    "    \n",
    "    if gr_truth_paths:\n",
    "        plt.subplot(1,k,4)\n",
    "        if use_cv2:\n",
    "            plt.imshow(cv2.imread(gr_truth_paths[i], 0))\n",
    "        else:\n",
    "            plt.imshow(Image.open(gr_truth_paths[i]))\n",
    "        plt.title(\"Ground truth\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
